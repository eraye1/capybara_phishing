[project]
name = "phishing-llm"
version = "0.1.0"
description = "LLaMA fine-tuning for phishing detection"
authors = [
    {name = "Capybara Team", email = "team@capybara.ai"}
]
dependencies = [
    "torch>=2.0.0",
    "transformers>=4.36.0",
    "datasets>=2.15.0",
    "accelerate>=0.25.0",
    "peft>=0.7.0",
    "bitsandbytes>=0.41.0",
    "wandb>=0.16.0",
    "hydra-core>=1.3.0",
    "pytest>=7.4.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "ruff>=0.1.0"
]
requires-python = ">=3.9"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src"]

[tool.black]
line-length = 100
target-version = ['py39']

[tool.isort]
profile = "black"
line_length = 100
multi_line_output = 3

[tool.ruff]
line-length = 100
target-version = "py39" 